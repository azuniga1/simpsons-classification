{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T17:53:56.755939Z",
     "start_time": "2017-06-19T17:53:52.584372Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import h5py\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import glob\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import train\n",
    "from random import shuffle\n",
    "import imp\n",
    "import os\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = [k.split('/')[2] for k in glob.glob('./characters/*') if len([p for p in glob.glob(k+'/*') if 'edited' in p or 'pic_vid' in p]) > 290]\n",
    "map_characters = dict(enumerate(characters))\n",
    "map_characters = {0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson', \n",
    "        3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel', \n",
    "        7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lisa_simpson', \n",
    "        11: 'marge_simpson', 12: 'milhouse_van_houten', 13: 'moe_szyslak', \n",
    "        14: 'ned_flanders', 15: 'nelson_muntz', 16: 'principal_skinner', 17: 'sideshow_bob'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\freeke01\\anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\freeke01\\anaconda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "imp.reload(train)\n",
    "model = train.load_model_from_checkpoint('./models/weights.best.hdf5', six_conv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_predict(image_path, all_perc=False):\n",
    "    image = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    pic = cv2.resize(image, (64,64))\n",
    "    a = model.predict_proba(pic.reshape(1, 64, 64,3))[0]\n",
    "    if all_perc:\n",
    "        print('\\n'.join(['{} : {}%'.format(map_characters[i], round(k*100)) for i,k in sorted(enumerate(a), key=lambda x:x[1], reverse=True)]))\n",
    "    else:\n",
    "        return map_characters[np.argmax(a)].replace('_',' ').title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "#     image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = np.array(bytearray(resp.read()))\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "def url_predict(url, all_perc=False):\n",
    "    image = url_to_image(url)\n",
    "#     img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    pic = cv2.resize(image, (64,64))\n",
    "    a = model.predict_proba(pic.reshape(1, 64, 64,3))[0]\n",
    "    if all_perc:\n",
    "        return \"Kevin\"\n",
    "        print('\\n'.join(['{} : {}%'.format(map_characters[i], round(k*100)) for i,k in sorted(enumerate(a), key=lambda x:x[1], reverse=True)]))\n",
    "    else:\n",
    "        print('\\n'.join(['{} : {}%'.format(map_characters[i], round(k*100)) for i,k in sorted(enumerate(a), key=lambda x:x[1], reverse=True)]))\n",
    "        return map_characters[np.argmax(a)].replace('_',' ').title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\resize.cpp:4044: error: (-215) ssize.width > 0 && ssize.height > 0 in function cv::resize\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-451e2acd48e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://vignette3.wikia.nocookie.net/simpsons/images/2/25/Adult_burns.jpg/revision/latest?cb=20111012170021\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://ilarge.lisimg.com/image/1786549/740full-ned-flanders.jpg\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0murl_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-bd4846e2d474>\u001b[0m in \u001b[0;36murl_predict\u001b[1;34m(url, all_perc)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#     plt.imshow(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#     plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mpic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall_perc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\resize.cpp:4044: error: (-215) ssize.width > 0 && ssize.height > 0 in function cv::resize\n"
     ]
    }
   ],
   "source": [
    "url = \"https://vignette3.wikia.nocookie.net/simpsons/images/2/25/Adult_burns.jpg/revision/latest?cb=20111012170021\"\n",
    "url = \"https://ilarge.lisimg.com/image/1786549/740full-ned-flanders.jpg\"\n",
    "url_predict(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  2,   2,  18],\n",
       "        [  2,   2,  26],\n",
       "        [  2,   2,  32],\n",
       "        ...,\n",
       "        [  5,   8, 170],\n",
       "        [  5,   8, 170],\n",
       "        [  4,  10, 169]],\n",
       "\n",
       "       [[  2,   2,  18],\n",
       "        [  2,   2,  26],\n",
       "        [  2,   2,  32],\n",
       "        ...,\n",
       "        [  5,   8, 170],\n",
       "        [  5,   8, 170],\n",
       "        [  4,  10, 169]],\n",
       "\n",
       "       [[  1,   1,  17],\n",
       "        [  2,   2,  26],\n",
       "        [  2,   2,  32],\n",
       "        ...,\n",
       "        [  5,   8, 170],\n",
       "        [  5,   8, 170],\n",
       "        [  3,  10, 167]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  1,   3,  44],\n",
       "        [  0,   4,  63],\n",
       "        [  0,   3,  68],\n",
       "        ...,\n",
       "        [  2,   8, 145],\n",
       "        [  0,   7, 130],\n",
       "        [  0,   6, 123]],\n",
       "\n",
       "       [[  1,   3,  44],\n",
       "        [  0,   4,  63],\n",
       "        [  0,   3,  68],\n",
       "        ...,\n",
       "        [  0,   9, 143],\n",
       "        [  0,   7, 130],\n",
       "        [  1,   6, 121]],\n",
       "\n",
       "       [[  2,   3,  47],\n",
       "        [  0,   3,  64],\n",
       "        [  0,   3,  68],\n",
       "        ...,\n",
       "        [  0,   9, 142],\n",
       "        [  1,   9, 130],\n",
       "        [  0,   5, 120]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://vignette3.wikia.nocookie.net/simpsons/images/2/25/Adult_burns.jpg/revision/latest?cb=20111012170021\"\n",
    "image2 = url_to_image(url)\n",
    "type(image2)\n",
    "image2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kev stuff above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T19:03:19.344136Z",
     "start_time": "2017-06-19T19:03:19.215728Z"
    }
   },
   "outputs": [],
   "source": [
    "characters = [k.split('/')[2] for k in glob.glob('./characters/*') if len([p for p in glob.glob(k+'/*') if 'edited' in p or 'pic_vid' in p]) > 290]\n",
    "map_characters = dict(enumerate(characters))\n",
    "map_characters = {0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson', \n",
    "        3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel', \n",
    "        7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lisa_simpson', \n",
    "        11: 'marge_simpson', 12: 'milhouse_van_houten', 13: 'moe_szyslak', \n",
    "        14: 'ned_flanders', 15: 'nelson_muntz', 16: 'principal_skinner', 17: 'sideshow_bob'}\n",
    "\n",
    "# map_characters = {0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T18:01:59.364496Z",
     "start_time": "2017-06-19T18:01:02.635237Z"
    }
   },
   "outputs": [],
   "source": [
    "imp.reload(train)\n",
    "## Just creating dataset\n",
    "X_train, X_test, y_train, y_test = train.get_dataset(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four convulational layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same pictures training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T21:03:04.590942Z",
     "start_time": "2017-06-19T21:02:37.945205Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Training in the notebook\n",
    "# X_train, X_test, y_train, y_test = train.get_dataset()\n",
    "`# model, opt = train.create_model_four_conv(X_train.shape[1:])\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=opt,\n",
    "#               metrics=['accuracy'])\n",
    "# model, history = train.training(model, X_train, X_test, y_train, y_test, data_augmentation=True, callback=True, six_conv=True)\n",
    "\n",
    "## Training on AWS\n",
    "# X_train, X_test, y_train, y_test = train.get_dataset(load=True)\n",
    "# model = keras.models.load_model('./models/model_08_06.h5')\n",
    "# with open('./models/history06_19.pkl', 'rb') as f:\n",
    "#     history = pickle.load(f)\n",
    "    \n",
    "## Loading from callbacks\n",
    "imp.reload(train)\n",
    "# model = train.load_model_from_checkpoint('./models/weights.best_6conv2.hdf5', six_conv=True)\n",
    "model = train.load_model_from_checkpoint('./models/weights.best.hdf5', six_conv=True)\n",
    "y_pred = model.predict(X_test)\n",
    "print('\\n', sklearn.metrics.classification_report(np.where(y_test > 0)[1], \n",
    "                                                  np.argmax(y_pred, axis=1), \n",
    "                                                  target_names=list(map_characters.values())), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:50:43.174450Z",
     "start_time": "2017-06-13T22:50:42.521287Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs= range(200)\n",
    "f, ax = plt.subplots(ncols=2, figsize=(15,6))\n",
    "ax[0].plot(epochs, history['loss'], label='loss')\n",
    "ax[0].plot(epochs, history['val_loss'], label='val_loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(epochs, history['acc'], label='acc')\n",
    "ax[1].plot(epochs, history['val_acc'], label='val_acc')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T22:07:18.729151Z",
     "start_time": "2017-06-19T22:07:18.310283Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./models/history06_19.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "epochs= range(40)\n",
    "f, ax = plt.subplots(ncols=2, figsize=(15,6))\n",
    "ax[0].plot(epochs, history['loss'], label='loss')\n",
    "ax[0].plot(epochs, history['val_loss'], label='val_loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(epochs, history['acc'], label='acc')\n",
    "ax[1].plot(epochs, history['val_acc'], label='val_acc')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T20:35:26.924628Z",
     "start_time": "2017-06-19T20:35:26.464445Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = sklearn.metrics.confusion_matrix(np.where(y_test > 0)[1], np.argmax(y_pred, axis=1))\n",
    "classes = list(map_characters.values())\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### With BGR/RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-05T23:18:19.686606Z",
     "start_time": "2017-06-05T23:18:08.010096Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test2 = []\n",
    "for img in X_test:\n",
    "    X_test2.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "X_test2 = np.array(X_test2)\n",
    "model = keras.models.load_model('./models/model_BGR.h5')\n",
    "y_pred = model.predict(X_test2)\n",
    "print('\\n', sklearn.metrics.classification_report(np.where(y_test > 0)[1], \n",
    "                                                  np.argmax(y_pred, axis=1), \n",
    "                                                  target_names=list(map_characters.values())), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Six convolutional layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T20:54:51.966888Z",
     "start_time": "2017-06-01T20:54:44.048799Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Training on AWS\n",
    "X_train, X_test, y_train, y_test = train.get_dataset(load=True)\n",
    "model = keras.models.load_model('./models/model_sixconv.h5')\n",
    "with open('./models/history2.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)\n",
    "y_pred = model.predict(X_test)\n",
    "print('\\n', sklearn.metrics.classification_report(np.where(y_test > 0)[1], \n",
    "                                                  np.argmax(y_pred, axis=1), \n",
    "                                                  target_names=list(map_characters.values())), sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T20:55:11.635466Z",
     "start_time": "2017-06-01T20:55:11.026225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs= range(40)\n",
    "f, ax = plt.subplots(ncols=2, figsize=(15,6))\n",
    "ax[0].plot(epochs, history['loss'], label='loss')\n",
    "ax[0].plot(epochs, history['val_loss'], label='val_loss')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(epochs, history['acc'], label='acc')\n",
    "ax[1].plot(epochs, history['val_acc'], label='val_acc')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T20:55:35.385798Z",
     "start_time": "2017-06-01T20:55:35.383200Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## -> More overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Predict from url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T23:48:06.070059Z",
     "start_time": "2017-05-31T23:48:06.050821Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "def url_to_image(url):\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "def plot_and_predict(url, all_perc=False):\n",
    "    image = url_to_image(url)\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    pic = cv2.resize(image, (pic_size,pic_size))\n",
    "    a = model.predict_proba(pic.reshape(1, pic_size, pic_size,3))[0]\n",
    "    if all_perc:\n",
    "        print('\\n'.join(['{} : {}%'.format(map_characters[i], round(k*100)) for i,k in sorted(enumerate(a), key=lambda x:x[1], reverse=True)]))\n",
    "    else:\n",
    "        return map_characters[np.argmax(a)].replace('_',' ').title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-31T23:49:55.637079Z",
     "start_time": "2017-05-31T23:49:55.256220Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = \"https://vignette3.wikia.nocookie.net/simpsons/images/2/25/Adult_burns.jpg/revision/latest?cb=20111012170021\"\n",
    "plot_and_predict(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-01T21:46:10.432344Z",
     "start_time": "2017-06-01T21:46:10.428738Z"
    },
    "collapsed": true
   },
   "source": [
    "#### Generating and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-08T20:00:24.737456Z",
     "start_time": "2017-06-08T20:00:22.193140Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "map_characters = {0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'bart_simpson', \n",
    "    3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'homer_simpson', \n",
    "    6: 'krusty_the_clown', 7: 'lisa_simpson', 8: 'marge_simpson', \n",
    "    9: 'milhouse_van_houten', 10: 'moe_szyslak', 11: 'ned_flanders', \n",
    "    12: 'principal_skinner', 13: 'sideshow_bob'}\n",
    "\n",
    "F = plt.figure(1, (15,20))\n",
    "grid = AxesGrid(F, 111,  # similar to subplot(141)\n",
    "                nrows_ncols=(3, 4),\n",
    "                axes_pad=0,\n",
    "                label_mode=\"1\")\n",
    "\n",
    "for i in range(12):\n",
    "    char = map_characters[i]\n",
    "    image = cv2.imread(np.random.choice([k for k in glob.glob('./characters/%s/*' % char) if 'pic_vid' in k]))\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    pic = cv2.resize(image, (64, 64)).astype('float32') / 255.\n",
    "    a = model.predict(pic.reshape(1, 64, 64,3))[0]\n",
    "    actual = char.split('_')[0].title()\n",
    "#     pred = map_characters[np.argmax(a)].split('_')[0].title()\n",
    "    text = sorted(['{:s} : {:.1f}%'.format(map_characters[k].split('_')[0].title(), 100*v) for k,v in enumerate(a)], \n",
    "       key=lambda x:float(x.split(':')[1].split('%')[0]), reverse=True)[:3]\n",
    "    img = cv2.resize(img, (352, 352))\n",
    "    cv2.rectangle(img, (0,260),(215,352),(255,255,255), -1)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img, 'Actual : %s' % actual, (10, 280), font, 0.7,(0,0,0),2,cv2.LINE_AA)\n",
    "    for k, t in enumerate(text):\n",
    "        cv2.putText(img, t,(10, 300+k*18), font, 0.65,(0,0,0),2,cv2.LINE_AA)\n",
    "#     cv2.putText(img, 'Pred : %s' % pred, (100, 310), font, 0.7,(0,0,0),2,cv2.LINE_AA)    \n",
    "    grid[i].imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Finding a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:54:54.679573Z",
     "start_time": "2017-06-13T22:54:41.559035Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=0)\n",
    "comp = np.argmax(y_test, axis=1) == np.argmax(y_pred, axis=1)\n",
    "index_good, index_false = [i for i, x in enumerate(comp) if x], [i for i, x in enumerate(comp) if not x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:55:17.358441Z",
     "start_time": "2017-06-13T22:55:17.344109Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "max_good = np.max(y_pred[index_good], axis=1)\n",
    "max_wrong = np.max(y_pred[index_false], axis=1)\n",
    "diff_good = np.diff(np.sort(y_pred[index_good], axis=1)[:, 16:])\n",
    "diff_wrong = np.diff(np.sort(y_pred[index_false], axis=1)[:, 16:])\n",
    "std_good = np.std(y_pred[index_good], axis=1)\n",
    "std_wrong = np.std(y_pred[index_false], axis=1)\n",
    "\n",
    "print(\"For good predictions : Max : {:.2f}, Difference Two First : {:.3f}, STD : {:.2f}\".format(np.mean(max_good),\n",
    "                                                                            np.mean(diff_good),\n",
    "                                                                            np.mean(std_good)))\n",
    "print(\"For wrong predictions : Max : {:.2f}, Difference Two First : {:.3f}, STD : {:.2f}\".format(np.mean(max_wrong),\n",
    "                                                                             np.mean(diff_wrong),\n",
    "                                                                            np.mean(std_wrong)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:55:19.136648Z",
     "start_time": "2017-06-13T22:55:18.400437Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(ncols=3, figsize=(19,6))\n",
    "ax[0].scatter(x = diff_good, y= max_good, c='red', marker='+', label = 'good pred')\n",
    "ax[0].scatter(x = diff_wrong, y= max_wrong, c='green', marker='o', label = 'wrong pred')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('Probability difference between the 2 best candidates')\n",
    "ax[0].set_ylabel('Probability of the best prediction')\n",
    "\n",
    "ax[1].scatter(x = diff_good, y= std_good, c='red', marker='+', label = 'good pred')\n",
    "ax[1].scatter(x = diff_wrong, y= std_wrong, c='green', marker='o', label = 'wrong pred')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Probability difference between the 2 best candidates')\n",
    "ax[1].set_ylabel('Standard deviation of the prediction')\n",
    "\n",
    "ax[2].scatter(x = max_good, y= std_good, c='red', marker='+', label = 'good pred')\n",
    "ax[2].scatter(x = max_wrong, y= std_wrong, c='green', marker='o', label = 'wrong pred')\n",
    "ax[2].legend()\n",
    "ax[2].set_xlabel('Probability of the best prediction')\n",
    "ax[2].set_ylabel('Standard deviation of the prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:53:23.345840Z",
     "start_time": "2017-06-13T22:53:23.333754Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## FOR LISA\n",
    "id_lisa = 10\n",
    "index_lisa = [i for i, x in enumerate(np.argmax(y_pred, axis= 1) == id_lisa) if x]\n",
    "index_good_lisa, index_wrong_lisa = [k for k in index_lisa if k in index_good], [k for k in index_lisa if k in index_false]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T22:53:42.314000Z",
     "start_time": "2017-06-13T22:53:41.741370Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dicts = {'max':{'good':np.max(y_pred[index_good_lisa], axis=1), \n",
    "                'wrong': np.max(y_pred[index_wrong_lisa], axis=1)},\n",
    "        'diff':{'good':np.diff(np.sort(y_pred[index_good_lisa], axis=1)[:, 16:]), \n",
    "                'wrong': np.diff(np.sort(y_pred[index_wrong_lisa], axis=1)[:, 16:])}, \n",
    "        'std':{'good': np.std(y_pred[index_good_lisa], axis=1), \n",
    "                'wrong': np.std(y_pred[index_wrong_lisa], axis=1)}}\n",
    "\n",
    "import itertools\n",
    "chosen = list(itertools.combinations(dicts.items(),2))\n",
    "f, ax = plt.subplots(ncols=3, figsize=(19,6))\n",
    "for i in range(3):\n",
    "    ax[i].scatter(x = chosen[i][0][1]['good'], y= chosen[i][1][1]['good'], \n",
    "                  c='red', marker='+', label = 'good pred')\n",
    "    ax[i].scatter(x = chosen[i][0][1]['wrong'], y= chosen[i][1][1]['wrong'], \n",
    "                  c='green', marker='o', label = 'wrong pred')\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(chosen[i][0][0])\n",
    "    ax[i].set_ylabel(chosen[i][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold and Precision/Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T00:18:50.913476Z",
     "start_time": "2017-06-14T00:18:38.064770Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=0)\n",
    "indices = [round(k*0.01,2) for k in range(0, 100, 5)] + [0.99]\n",
    "pos_characters = {cl: {k:[] for k in indices} for cl in map_characters}\n",
    "for k in indices:\n",
    "    for i, e in enumerate(y_pred):\n",
    "        if np.max(e) > k:\n",
    "            pos_characters[np.argmax(e)][k].append(int(np.argmax(e) == np.argmax(y_test[i])))\n",
    "pos_characters['ALL'] = {k:np.sum([pos_characters[cl][k] for cl in pos_characters]) for k in indices}                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T01:05:43.502988Z",
     "start_time": "2017-06-14T01:05:41.869969Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = [round(k*0.01, 2)+round(p*0.01,2) for k,p in zip(range(0, 20), range(0, 100, 5))]\n",
    "pos_characters_2 = {cl: {k:[] for k in indices} for cl in map_characters}\n",
    "for k in indices:\n",
    "    for i, e in enumerate(y_pred):\n",
    "        if np.std(e)+np.max(e) > k:\n",
    "            pos_characters_2[np.argmax(e)][k].append(int(np.argmax(e) == np.argmax(y_test[i])))\n",
    "pos_characters_2['ALL'] = {k:np.sum([pos_characters_2[cl][k] for cl in pos_characters_2]) for k in indices}                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T00:41:08.113571Z",
     "start_time": "2017-06-14T00:41:07.066020Z"
    }
   },
   "outputs": [],
   "source": [
    "classes_plot = [\"ALL\", 10, 7, 15, 2, 11]\n",
    "tr = {\"ALL\": np.argmax(y_test, axis=1)}\n",
    "f, ax = plt.subplots(ncols=len(classes_plot), figsize=(len(classes_plot)*5, 5))\n",
    "for i, cl_plt in enumerate(classes_plot):\n",
    "    precision = {k:np.sum(pos_characters[cl_plt][k])/len(pos_characters[cl_plt][k]) for k in indices}\n",
    "    recall = {k:np.sum(pos_characters[cl_plt][k])/np.sum(np.argmax(y_test, axis=1)==tr.get(cl_plt, cl_plt))for k in indices}\n",
    "    f1_score = {k:(2*precision[k]*recall[k])/(precision[k]+recall[k]) for k in indices}\n",
    "    x,y = zip(*sorted(precision.items()))\n",
    "    ax[i].plot(x, y, color='blue', label='Precision')\n",
    "    x,y = zip(*sorted(recall.items()))\n",
    "    ax[i].plot(x, y, label='Recall', color='green')\n",
    "    x,y = zip(*sorted(f1_score.items()))\n",
    "    ax[i].plot(x, y, color='red', label='F1 Score')\n",
    "    _ = ax[i].set_xlim((0,1))\n",
    "    _ = ax[i].set_ylabel('Score')\n",
    "    _ = ax[i].set_xlabel('Threshold (Probability minimum for predicted class)')\n",
    "    _ = ax[i].set_ylim((0.3,1))\n",
    "    _ = ax[i].legend()\n",
    "    _ = ax[i].set_title('Class : %s \\n(Test set size : %d)' % (map_characters.get(cl_plt, cl_plt), np.sum(np.argmax(y_test, axis=1) == tr.get(cl_plt, cl_plt))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Attention maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-09T23:35:47.084345Z",
     "start_time": "2017-06-09T23:35:42.120419Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from vis.utils import utils\n",
    "from vis.visualization import visualize_saliency\n",
    "\n",
    "# The name of the layer we want to visualize\n",
    "# (see model definition in vggnet.py)\n",
    "layer_idx = [idx for idx, layer in enumerate(model.layers)][16]\n",
    "\n",
    "# Images corresponding to tiger, penguin, dumbbell, speedboat, spider\n",
    "image_paths = np.random.choice(np.concatenate([glob.glob('./characters/%s/*.jpg' % k) for k in map_characters.values()]), 3)\n",
    "\n",
    "heatmaps = []\n",
    "true_img = []\n",
    "d=[]\n",
    "for path in image_paths:\n",
    "    seed_img = utils.load_img(path, target_size=(64, 64)).astype('float32') / 255.\n",
    "    seed_img  = seed_img.reshape((1, 64, 64, 3))\n",
    "    pred_class = np.argmax(model.predict(seed_img))\n",
    "\n",
    "    # Here we are asking it to show attention such that prob of `pred_class` is maximized.\n",
    "    heatmap = visualize_saliency(model, layer_idx, [pred_class], seed_img.reshape((64, 64, 3)))\n",
    "    heatmaps.append(heatmap * 255.) \n",
    "    true_img.append(cv2.resize(cv2.imread(path),(480,640)))\n",
    "    d.append(cv2.resize(cv2.imread(path),(480,640)) + cv2.resize(heatmap,(480,640)))\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(utils.stitch_images(true_img))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(utils.stitch_images(d))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Create video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-12T23:35:07.383218Z",
     "start_time": "2017-06-12T23:35:06.988568Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m, s = 5, 7\n",
    "cap = cv2.VideoCapture(\"video1.avi\") \n",
    "nb_frames = 2500\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.set(1, fps*(m*60+s))\n",
    "for i in range(4000):\n",
    "    ret, frame = cap.read()\n",
    "    if i % 15 == 0:\n",
    "        img = cv2.resize(frame, (64, 64)).astype('float32') / 255.\n",
    "        a = model.predict(img.reshape((-1, 64, 64, 3)), verbose=0)[0]\n",
    "        text = sorted(['{:s} : {:.1f}%'.format(map_characters[k].split('_')[0].title(), 100*v) for k,v in enumerate(a)], \n",
    "               key=lambda x:float(x.split(':')[1].split('%')[0]), reverse=True)[:3]\n",
    "    im = frame\n",
    "    cv2.rectangle(im, (int(frame.shape[1] * 0.6),int(frame.shape[0] * 0.7)),(frame.shape[1],frame.shape[0]),(255,255,255), -1)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for k, t in enumerate(text):\n",
    "        cv2.putText(im,t,\n",
    "                    ((int(frame.shape[1] * 0.6 + 10), int(frame.shape[0] * 0.7 + 20 +k*25))), \n",
    "                    font, 0.8,(0,0,0),2,cv2.LINE_AA)\n",
    "    cv2.imwrite('./video_created/vid_{0:0=4d}.jpg'.format(i), im)\n",
    " \n",
    "# !ffmpeg -f image2 -r 25 -i ./video_created/vid_%04d.jpg -vcodec mpeg4 -y ./video_created/movie3.mp4\n",
    "\n",
    "# for i in glob.glob('./video_created/*.jpg'):\n",
    "#     os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-08T21:15:59.958414Z",
     "start_time": "2017-06-08T21:15:56.756799Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!ffmpeg -f image2 -r 25 -i ./video_created/video_%05d.jpg -vcodec mpeg4 -y ./video_created/movie4.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
